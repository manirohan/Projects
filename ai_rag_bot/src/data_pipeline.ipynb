{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b46b1a-02fb-4261-9000-f6eb824a00be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved paper 1: URECA: Unique Region Caption Anything...\n",
      "✅ Saved paper 2: SmolVLM: Redefining small and efficient multimodal models...\n",
      "✅ Saved paper 3: Dion: A Communication-Efficient Optimizer for Large Models...\n",
      "✅ Saved paper 4: The challenge of uncertainty quantification of large languag...\n",
      "✅ Saved paper 5: How to evaluate control measures for LLM agents? A trajector...\n",
      "✅ Saved paper 6: Learning to Reason Over Time: Timeline Self-Reflection for I...\n",
      "✅ Saved paper 7: Explaining Low Perception Model Competency with High-Compete...\n",
      "✅ Saved paper 8: Adversarial KA...\n",
      "✅ Saved paper 9: PINNverse: Accurate parameter estimation in differential equ...\n",
      "✅ Saved paper 10: Mapping biodiversity at very-high resolution in Europe...\n",
      "✅ Saved paper 11: FinGrAct: A Framework for FINe-GRrained Evaluation of ACTion...\n",
      "✅ Saved paper 12: Leveraging LLMs for Utility-Focused Annotation: Reducing Man...\n",
      "✅ Saved paper 13: Unleashing the Power of LLMs in Dense Retrieval with Query L...\n",
      "✅ Saved paper 14: A moving target in AI-assisted decision-making: Dataset shif...\n",
      "✅ Saved paper 15: Correcting Class Imbalances with Self-Training for Improved ...\n",
      "✅ Saved paper 16: 3D Universal Lesion Detection and Tagging in CT with Self-Tr...\n",
      "✅ Saved paper 17: Universal Lymph Node Detection in Multiparametric MRI with S...\n",
      "✅ Saved paper 18: Resource-Efficient Beam Prediction in mmWave Communications ...\n",
      "✅ Saved paper 19: Lightweight and Direct Document Relevance Optimization for G...\n",
      "✅ Saved paper 20: BRIDGES: Bridging Graph Modality and Large Language Models w...\n",
      "✅ Saved paper 21: Attention-Based Multi-Scale Temporal Fusion Network for Unce...\n",
      "✅ Saved paper 22: SSLFusion: Scale & Space Aligned Latent Fusion Model for Mul...\n",
      "✅ Saved paper 23: RLBayes: a Bayesian Network Structure Learning Algorithm via...\n",
      "✅ Saved paper 24: Evaluating Knowledge Graph Based Retrieval Augmented Generat...\n",
      "✅ Saved paper 25: Leveraging Label Potential for Enhanced Multimodal Emotion R...\n"
     ]
    }
   ],
   "source": [
    "# src/data_pipeline.py\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "ARXIV_API_URL = \"http://export.arxiv.org/api/query\"\n",
    "SAVE_DIR = \"data/raw_papers\"\n",
    "\n",
    "def fetch_arxiv_papers(query=\"cs.AI\", max_results=50):\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    params = {\n",
    "        \"search_query\": f\"cat:{query}\",\n",
    "        \"start\": 0,\n",
    "        \"max_results\": max_results,\n",
    "        \"sortBy\": \"submittedDate\",\n",
    "        \"sortOrder\": \"descending\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(ARXIV_API_URL, params=params)\n",
    "    root = ET.fromstring(response.content)\n",
    "\n",
    "    ns = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "    entries = root.findall('atom:entry', ns)\n",
    "\n",
    "    for i, entry in enumerate(entries):\n",
    "        title = entry.find('atom:title', ns).text.strip()\n",
    "        abstract = entry.find('atom:summary', ns).text.strip()\n",
    "        paper_id = entry.find('atom:id', ns).text.split('/')[-1]\n",
    "        authors = [author.find('atom:name', ns).text for author in entry.findall('atom:author', ns)]\n",
    "\n",
    "        paper = {\n",
    "            \"id\": paper_id,\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract,\n",
    "            \"authors\": authors\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(SAVE_DIR, f\"{paper_id}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            import json\n",
    "            json.dump(paper, f, indent=2)\n",
    "\n",
    "        print(f\"✅ Saved paper {i+1}: {title[:60]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_arxiv_papers(query=\"cs.AI\", max_results=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0219ac7e-9ab9-4914-9a37-05c50fcb313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved paper 1: URECA: Unique Region Caption Anything...\n",
      "✅ Saved paper 2: SmolVLM: Redefining small and efficient multimodal models...\n",
      "✅ Saved paper 3: Dion: A Communication-Efficient Optimizer for Large Models...\n",
      "✅ Saved paper 4: The challenge of uncertainty quantification of large languag...\n",
      "✅ Saved paper 5: How to evaluate control measures for LLM agents? A trajector...\n",
      "✅ Saved paper 6: Learning to Reason Over Time: Timeline Self-Reflection for I...\n",
      "✅ Saved paper 7: Explaining Low Perception Model Competency with High-Compete...\n",
      "✅ Saved paper 8: Adversarial KA...\n",
      "✅ Saved paper 9: PINNverse: Accurate parameter estimation in differential equ...\n",
      "✅ Saved paper 10: Mapping biodiversity at very-high resolution in Europe...\n",
      "✅ Saved paper 11: FinGrAct: A Framework for FINe-GRrained Evaluation of ACTion...\n",
      "✅ Saved paper 12: Leveraging LLMs for Utility-Focused Annotation: Reducing Man...\n",
      "✅ Saved paper 13: Unleashing the Power of LLMs in Dense Retrieval with Query L...\n",
      "✅ Saved paper 14: A moving target in AI-assisted decision-making: Dataset shif...\n",
      "✅ Saved paper 15: Correcting Class Imbalances with Self-Training for Improved ...\n",
      "✅ Saved paper 16: 3D Universal Lesion Detection and Tagging in CT with Self-Tr...\n",
      "✅ Saved paper 17: Universal Lymph Node Detection in Multiparametric MRI with S...\n",
      "✅ Saved paper 18: Resource-Efficient Beam Prediction in mmWave Communications ...\n",
      "✅ Saved paper 19: Lightweight and Direct Document Relevance Optimization for G...\n",
      "✅ Saved paper 20: BRIDGES: Bridging Graph Modality and Large Language Models w...\n",
      "✅ Saved paper 21: Attention-Based Multi-Scale Temporal Fusion Network for Unce...\n",
      "✅ Saved paper 22: SSLFusion: Scale & Space Aligned Latent Fusion Model for Mul...\n",
      "✅ Saved paper 23: RLBayes: a Bayesian Network Structure Learning Algorithm via...\n",
      "✅ Saved paper 24: Evaluating Knowledge Graph Based Retrieval Augmented Generat...\n",
      "✅ Saved paper 25: Leveraging Label Potential for Enhanced Multimodal Emotion R...\n",
      "✅ Processed & chunked 2504.05181v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05255v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05259v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05172v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05158v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05170v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05210v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05187v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05220v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05216v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05254v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05229v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05180v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05258v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05201v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05248v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05163v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05207v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05231v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05167v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05299v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05295v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05305v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05278v1 into 1 chunks\n",
      "✅ Processed & chunked 2504.05196v1 into 1 chunks\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from textwrap import wrap\n",
    "\n",
    "PROCESSED_DIR = \"data/processed_chunks\"\n",
    "CHUNK_SIZE = 500  # Approximate number of tokens per chunk\n",
    "\n",
    "def clean_text(text):\n",
    "    # Basic cleanup: remove newlines, LaTeX, extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\$.*?\\$', '', text)  # Remove inline LaTeX\n",
    "    return text.strip()\n",
    "\n",
    "def chunk_text(text, chunk_size=CHUNK_SIZE):\n",
    "    # Simple character-based splitting\n",
    "    sentences = wrap(text, width=chunk_size * 5)  # Approx. chars to match token size\n",
    "    return sentences\n",
    "\n",
    "def process_and_chunk_papers():\n",
    "    os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "    raw_files = Path(SAVE_DIR).glob(\"*.json\")\n",
    "\n",
    "    for file_path in raw_files:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            paper = json.load(f)\n",
    "\n",
    "        abstract = clean_text(paper.get(\"abstract\", \"\"))\n",
    "        chunks = chunk_text(abstract)\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_file = f\"{paper['id']}_chunk_{i}.txt\"\n",
    "            with open(os.path.join(PROCESSED_DIR, chunk_file), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(chunk)\n",
    "\n",
    "        print(f\"✅ Processed & chunked {paper['id']} into {len(chunks)} chunks\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_arxiv_papers(query=\"cs.AI\", max_results=25)\n",
    "    process_and_chunk_papers()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
