objects and answer questions. (Right)Throughput in tokens per second on NVIDIA A 100GPUs(top)and different consumer personal computers (bottom) across different batch sizes and model variants. larger language models provide enhanced context management and improved multimodal reasoning, benefiting both language-intensive and vision-centric tasks. Comparison with Other Compact VLMs. Figure 1 situates SmolVLM- 2.2B among recent small-scale VLMs by comparing OpenCompass benchmark performance against GPU memory consumption per image. SmolVLM- 2.2B achieves notably strong performance on MathVista ( 51.5) and ScienceQA ( 90.0), while maintaining exceptionally low GPU usage of just 4.9GB VRAM. In contrast, models requiring significantly more compute, such as Qwen 2VL-2B and InternVL 2-2B, aren’t clearly better performers. Specifically, Qwen 2VL-2B slightly surpasses SmolVLM- 2.2B on AI 2D (74.7vs.70.0) and ChartQA ( 73.5vs.68.8), yet falls short on MathVista (48.0vs.51.5) and ScienceQA ( 78.7vs.90.0). Similarly, InternVL2- 2B achieves higher scores on ScienceQA (94.1vs.90.0) and MMStar ( 49.8vs.46.0), but at more than double the VRAM cost. Further comparisons highlight distinct trade-offs among size, memory footprint, and task-specific performance. MiniCPM-V2 ( 2.8B parameters) underperforms SmolVLM- 2.2B on most benchmarks. Other models such as Moondream2 and PaliGemma (both around 2˘3B parameters) exhibit significant variance across tasks: Moon- dream2, for instance, scores well on ChartQA ( 72.2) with just 3.9GB VRAM but substantially underperforms on MMMU ( 29.3). Conversely, PaliGemma excels at ScienceQA ( 94.3) yet struggles on ChartQA ( 33.7). This variability underscores how specialized training impacts per-task. VideoBenchmarks. Table 1 provides comprehensive results across five diverse video benchmarks: Video-MME, MLVU, MVBench, TempCompass, and WorldSense. SmolVLM- 2.2B notably excels at Video-MME ( 52.1) and WorldSense ( 36.2), outperforming significantly larger models such as Qwen 2VL-7B ( 32.4on WorldSense), showcasing strong capabilities in complex multimodal video comprehension tasks. The SmolVLM- 500M variant also demonstrates robust performance, achieving competitive scores on TempCompass ( 49.0) and