optimized ONNX (Open Neural Network Exchange) exports, facilitating cross-platform compatibility and broadening deployment opportunities across consumer-grade hardware targets. Notably, we demonstrate the ability to efficiently run these models locally within a browser environment via WebGPU, with the 256M variant achieving up to 80decode tokens per second on a 14-inch MacBook Pro (M 4Max). 4.5 Downstream Applications Beyond our own evaluations, SmolVLM has seen adoption in various downstream applications developed by the broader research community, emphasizing its efficiency in real-world, resource-constrained scenarios. ColSmolVLM: On-Device Multimodal Inference. ColSmolVLM utilizes the smaller SmolVLM variants ( 256M and500M parameters) designed explicitly for on-device deployment, as detailed in recent work by Hugging Face (Faysse et al., 2024b). These compact models enable efficient multimodal inference directly on mobile devices, consumer laptops, and even within browser-based environments, significantly lowering computational demands and operational costs. Smol Docling: Ultra-Compact Document Processing. Smol Docling is an ultra-compact 256M-parameter variant of SmolVLM, optimized explicitly for end-to-end multimodal document conversion tasks (Nassar et al., 2025b). By employing specialized representations known as DocTags, Smol Docling efficiently captures content, context, and spatial relationships across diverse document types, including business documents, academic papers, and patents. Its compact architecture maintains competitive performance with considerably larger VLMs, highlighting its suitability for deployment in scenarios with computational constraints. BioVQA: Biomedical Visual Question Answering. BioVQA leverages SmolVLMâ€™s compact and efficient architecture to address visual question answering tasks within the biomedical domain (Lozano et al., 2025). Small-scale SmolVLM models have demonstrated promising capabilities in interpreting medical images, assisting healthcare professionals by providing accurate answers to clinical questions based on visual data. This capability is particularly valuable in healthcare settings where quick, reliable image interpretation is critical, yet computational resources may be limited. 5 Related Work 5.1 First-Generation Vision-Language Models Early multimodal models achieved significant progress primarily by scaling parameters, but