al., 2024), The Stack (Kocetkov et al., 2022)) and short-context sources (FineWeb-Edu (Penedo et al., 2024), DCLM (Li et al., 2024a), and math from SmolLM2). 3 Figure 4 ∣Pixel shuffle. Rearranges encoded images, trading spatial resolution for increased channel depth. This reduces visual token count while preserving information density. While fine-tuning was stable at 16k tokens for the 1.7B LM, smaller models (135M, 360M) struggled beyond 8k. Experiments with our 2.2B SmolVLM confirmed consistent performance gains up to 16k tokens (Figure 3, middle). Accordingly, we adopt a 16k-token context for SmolVLM and an 8k-token limit for smaller variants. Finding 2. Compact VLMs significantly benefit from extended context lengths. Extending the context window alone is not sufficient. Recent VLMs (e.g., MM1 (McKinzie et al., 2024), MiniCPM-V (Yao et al., 2024), InternVL (Chen et al., 2024c)) combine the self-attention architecture with token compression techniques (Zohar et al., 2024b; Laurençon et al., 2024) to fit longer sequences efficiently and reduce computational overhead. One particularly effective compression method is pixel shuffle (space-to-depth), initially proposed for super- resolution tasks (Shi et al., 2016) and recently adopted by Idefics3. Pixel shuffle rearranges spatial features into additional channels, reducing spatial resolution but increasing representational density (Figure 4). This reduces the total number of visual tokens by a factor of r2, where ris the shuffle ratio. However, higher ratios collapse larger spatial regions into single tokens, impairing tasks requiring precise localization, such as OCR. Models like InternVL and Idefics 3user=2to balance compression and spatial fidelity. In contrast, our experiments (Figure 3, right) show that smaller VLMs benefit from more aggressive compression ( r=4) as the reduced token count eases attention overhead and improves long-context modeling. Finding 3. Small VLMs benefit from more aggressive visual token compression. 2.3 How can we efficiently encode images and videos? Balancing token allocation