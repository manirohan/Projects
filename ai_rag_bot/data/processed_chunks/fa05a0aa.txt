experiments (Figure 3, right) show that smaller VLMs benefit from more aggressive compression ( r=4) as the reduced token count eases attention overhead and improves long-context modeling. Finding 3. Small VLMs benefit from more aggressive visual token compression. 2.3 How can we efficiently encode images and videos? Balancing token allocation between images and videos is crucial for efficient multimodal modeling: images benefit from higher resolution and more tokens to retain fidelity, whereas videos typically require fewer tokens per frame to handle longer sequences efficiently. To achieve this, we successfully adopted an image-splitting strategy inspired by UReader (Ye et al., 2023) and SPHINX (Lin et al., 2023b), where high-resolution images are divided into multiple sub-images along with a downsized version of the original. This approach proved effective in maintaining image quality without excessive computational overhead. For videos, however, we found that strategies such as frame averaging, inspired by Liu et al. (2024f), negatively impacted performance. As shown in Figure 3 (right), combining multiple frames significantly degraded OpenCompass-Video results, particularly at higher averaging factors (2,4,8). Consequently, frame averaging was excluded from SmolVLM’s final design, and video frames were instead rescaled to the resolution of the image encoder. Finding 4. For small models, image splitting enhances performance for vision tasks, whereas video frame averaging does not. 4 Figure 5 ∣Tokenization Strategy Comparisons. (Left)Training loss curves illustrating the “OCR loss plague” when using string-based tokens in smaller models. (Center) Aggregated evaluation metrics showing consistently higher scores with learned tokens (orange). (Right)Scatter plot of OpenCompass-Image vs. OpenCompass-Video: learned tokens dominate the higher-scoring region, especially in image-intensive tasks. 3 Smol Instruction Tuning Smol instruction tuning requires careful vision (§3.1) and text tokenization (§3.2), alongside unified methods for multimodal modeling under tight compute constraints. Learned positional tokens and structured prompts stabilize training and improve OCR, but data